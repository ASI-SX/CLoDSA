{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Instance_Segmentation_JSON.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxQekSqTht6I"
   },
   "source": [
    "# Augmenting a dataset for instance segmentation\n",
    "\n",
    "In this notebook, we illustrate how CLODSA can be employed to augment a dataset of images devoted to instance segmentation that was annotated using a special purpose JSON format created using [AnnotationJ](https://github.com/joheras/CLoDSA/tree/master/AnnotationJ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YC_9o6-Jht6M"
   },
   "source": [
    "We will use a small dataset of shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3838
    },
    "colab_type": "code",
    "id": "QNhd1Ttiht6Q",
    "outputId": "0268f0b6-eecc-436a-ee85-05915b5f5dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-24 08:46:50--  https://www.dropbox.com/s/607kkh0suq7u48s/shapes-json.zip?dl=0\n",
      "Resolviendo www.dropbox.com (www.dropbox.com)... 162.125.68.1, 2620:100:6024:1::a27d:4401\n",
      "Conectando con www.dropbox.com (www.dropbox.com)[162.125.68.1]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 301 Moved Permanently\n",
      "Ubicación: /s/raw/607kkh0suq7u48s/shapes-json.zip [siguiente]\n",
      "--2019-01-24 08:46:50--  https://www.dropbox.com/s/raw/607kkh0suq7u48s/shapes-json.zip\n",
      "Reutilizando la conexión con www.dropbox.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: https://uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com/cd/0/inline/AZ-0SNyTjY-r-GnrOIOAE320pVS5QYRME7QCBrabwBkbRHGX7hV0Y-oNW5-Dhem3VYDL10SKqtNYa_waVsnSTt5YDoVc7Htvzc2V9NIlSyK0EW21V-QXlgykAPEFpO0YBxE/file# [siguiente]\n",
      "--2019-01-24 08:46:50--  https://uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com/cd/0/inline/AZ-0SNyTjY-r-GnrOIOAE320pVS5QYRME7QCBrabwBkbRHGX7hV0Y-oNW5-Dhem3VYDL10SKqtNYa_waVsnSTt5YDoVc7Htvzc2V9NIlSyK0EW21V-QXlgykAPEFpO0YBxE/file\n",
      "Resolviendo uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com (uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com)... 162.125.68.6, 2620:100:6024:6::a27d:4406\n",
      "Conectando con uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com (uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com)[162.125.68.6]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 FOUND\n",
      "Ubicación: /cd/0/inline2/AZ8x-T7lrqDArsUiUfX8GrlvN3A5R9629oCqhj3FGCrWhVDmxzoejRGTlRE7xd4Udx0yWK9f2i0C0w3OPce3zT3JpnnHU2eZFE7tiGHbxqXSxLn-1BnYk1bZkopI52EAJ8-sJgfIf3dUr5uxcR5ypKwugEgEaYTbx5GRggMEefWrhnYjY4kgg186GZYabyo1jCOfQZmjcMUI2MyH6mtlpGgVdjFIREqo842EJZ2VgurStF04Jql-9YcYdHlqc-5FFx8m20v-DRHfh2eZKUwjemD3KeJ3UmkYLnQxhAuHyUivTkL4Zy38nPmbXvgoxaz3-5cRng1XD_orTfSMC33k8CUMvwFmZXKkC8ywp1d34VsdKw/file [siguiente]\n",
      "--2019-01-24 08:46:51--  https://uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com/cd/0/inline2/AZ8x-T7lrqDArsUiUfX8GrlvN3A5R9629oCqhj3FGCrWhVDmxzoejRGTlRE7xd4Udx0yWK9f2i0C0w3OPce3zT3JpnnHU2eZFE7tiGHbxqXSxLn-1BnYk1bZkopI52EAJ8-sJgfIf3dUr5uxcR5ypKwugEgEaYTbx5GRggMEefWrhnYjY4kgg186GZYabyo1jCOfQZmjcMUI2MyH6mtlpGgVdjFIREqo842EJZ2VgurStF04Jql-9YcYdHlqc-5FFx8m20v-DRHfh2eZKUwjemD3KeJ3UmkYLnQxhAuHyUivTkL4Zy38nPmbXvgoxaz3-5cRng1XD_orTfSMC33k8CUMvwFmZXKkC8ywp1d34VsdKw/file\n",
      "Reutilizando la conexión con uc2c2a50746355f206652cfbce50.dl.dropboxusercontent.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 12128 (12K) [application/zip]\n",
      "Guardando como: “shapes-json.zip”\n",
      "\n",
      "shapes-json.zip     100%[===================>]  11,84K  --.-KB/s    en 0s      \n",
      "\n",
      "2019-01-24 08:46:52 (130 MB/s) - “shapes-json.zip” guardado [12128/12128]\n",
      "\n",
      "Archive:  shapes-json.zip\n",
      "   creating: shapes-json/\n",
      "  inflating: shapes-json/1.jpeg      \n",
      "  inflating: shapes-json/1.txt       \n",
      "  inflating: shapes-json/2.jpeg      \n",
      "  inflating: shapes-json/2.txt       \n",
      "  inflating: shapes-json/3.jpeg      \n",
      "  inflating: shapes-json/3.txt       \n",
      "  inflating: shapes-json/4.jpeg      \n",
      "  inflating: shapes-json/4.txt       \n",
      "  inflating: shapes-json/5.jpeg      \n",
      "  inflating: shapes-json/5.txt       \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/607kkh0suq7u48s/shapes-json.zip?dl=0 -O shapes-json.zip\n",
    "!unzip shapes-json.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAy0Hvnbht6i"
   },
   "source": [
    "We can check the elements of the shapes folder that are 5 images and their annotations (in txt files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "XEJ0pRfRht6k",
    "outputId": "9cc7906d-f241-403d-b41e-7b8b4ff9112c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpeg\t1.txt  2.jpeg  2.txt  3.jpeg  3.txt  4.jpeg  4.txt  5.jpeg  5.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls shapes-json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir output-json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaBilQHUht6u"
   },
   "source": [
    "## Augmentation techniques\n",
    "\n",
    "For this example, we consider three augmentation techniques. \n",
    "\n",
    "The augmentation techniques applied in this example are:\n",
    "- Rotation.\n",
    "- Flip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCILufF2ht6y"
   },
   "source": [
    "## Installing the necessary libraries\n",
    "\n",
    "In case that CLODSA is not installed in your system, the first task consists in installing it using ``pip``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "FWTm8dG3ht6y",
    "outputId": "ae3a8866-cbfb-4863-a357-248e1e56989c"
   },
   "outputs": [],
   "source": [
    "!pip install clodsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1q3x_OFht66"
   },
   "source": [
    "## Loading the necessary libraries\n",
    "\n",
    "The first step in the pipeline consists in loading the necessary libraries to apply the data augmentation techniques in CLODSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JqWBswFyht68",
    "outputId": "77349188-126d-4e4d-93fa-929ec33ad573"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
    "from clodsa.transformers.transformerFactory import transformerGenerator\n",
    "from clodsa.techniques.techniqueFactory import createTechnique\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBP59dqqht7E"
   },
   "source": [
    "## Creating the augmentor object\n",
    "\n",
    "As explained in the documentation of CLODSA, we need to specify some parameters for the augmentation process, and use them to create an augmentor object.  \n",
    "\n",
    "_The kind of problem_. In this case, we are working in an instance segmentation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQ5q8WVnht7G"
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"instance_segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D46gdf-4ht7K"
   },
   "source": [
    "_The annotation mode_. The annotation is provided using a json file with the same name as each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrlRg-FVht7M"
   },
   "outputs": [],
   "source": [
    "ANNOTATION_MODE = \"json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cn-uF33Oht7S"
   },
   "source": [
    "_The input path_. The input path containing the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78jPXCj2ht7U"
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = \"shapes-json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9kGGhs4ht7a"
   },
   "source": [
    "_The generation mode_. In this case, linear, that is, all the augmentation techniques are applied to all the images of the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCweCzLeht7c"
   },
   "outputs": [],
   "source": [
    "GENERATION_MODE = \"linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6WljljVht7g"
   },
   "source": [
    "_The output mode_. The generated images will be stored in a new folder called output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4uKKcJUht7i"
   },
   "outputs": [],
   "source": [
    "OUTPUT_MODE = \"json\"\n",
    "OUTPUT_PATH= \"output-json/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9R79LEvVht7o"
   },
   "source": [
    "Using the above information, we can create our augmentor object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQ9wyiQuht7q"
   },
   "outputs": [],
   "source": [
    "augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXOfuq90ht7w"
   },
   "source": [
    "## Adding the augmentation techniques\n",
    "\n",
    "Now, we define the techniques that will be applied in our augmentation process and add them to our augmentor object. To illustrate the transformations, we will use the following image of the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we must define a transformer generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformerGenerator(PROBLEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4PfSKW-ht74"
   },
   "source": [
    "_Rotations:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajKE-mkDht74"
   },
   "outputs": [],
   "source": [
    "for angle in [90,180]:\n",
    "    rotate = createTechnique(\"rotate\", {\"angle\" : angle})\n",
    "    augmentor.addTransformer(transformer(rotate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Flips:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = createTechnique(\"flip\",{\"flip\":1})\n",
    "augmentor.addTransformer(transformer(flip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwE-qSYLht9I"
   },
   "source": [
    "## Applying the augmentation process\n",
    "\n",
    "Finally, we apply the augmentation process (this might take some time depending on the number of images of the original dataset and the number of transformations that will be applied). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbW5YVE9ht9I"
   },
   "outputs": [],
   "source": [
    "augmentor.applyAugmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the elements of the output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_1.jpeg  0_3.jpeg  0_5.jpeg  1_2.jpeg\t1_4.jpeg  2_1.jpeg  2_3.jpeg  2_5.jpeg\r\n",
      "0_1.txt   0_3.txt   0_5.txt   1_2.txt\t1_4.txt   2_1.txt   2_3.txt   2_5.txt\r\n",
      "0_2.jpeg  0_4.jpeg  1_1.jpeg  1_3.jpeg\t1_5.jpeg  2_2.jpeg  2_4.jpeg\r\n",
      "0_2.txt   0_4.txt   1_1.txt   1_3.txt\t1_5.txt   2_2.txt   2_4.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls output-json/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are executing this notebook in Colaboratory, you need to download the generated files. To that aim, you can create a zip folder and download it using the following commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r output-json.zip output-json\n",
    "from google.colab import files\n",
    "files.download('output-json.zip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CLODSA_Nuclei.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
