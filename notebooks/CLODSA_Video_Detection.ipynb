{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Video_Detection.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLTwDWw0ni8G"
   },
   "source": [
    "# Augmenting a dataset for action recognition in videos\n",
    "\n",
    "In this notebook, we illustrate how CLODSA can be employed to augment a dataset of videos devoted to object detection. In particular, we use the [Youtube bounding boxes dataset](https://research.google.com/youtube-bb/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPDdsBtFni8I"
   },
   "source": [
    "The Youtube bounding boxes dataset contains 240000 videos. In our case, we will use a subset of this dataset to illustrate the use of CLoDSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4024
    },
    "colab_type": "code",
    "id": "FbGwos-bni8K",
    "outputId": "3151302c-730f-4c18-d751-3dd36c4ed51d"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/z36klo4mw79ptv0/youtube.zip?dl=0 -O youtube.zip\n",
    "!unzip youtube.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmaoZcYXni8Y"
   },
   "source": [
    "We can check the amount of videos in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "yXoVkFkqni8a",
    "outputId": "55518f50-f4a3-4273-e5a5-dec4c2bd51fe"
   },
   "outputs": [],
   "source": [
    "print(\"Youtube folders\")\n",
    "!ls youtube/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMaT8vnzni8i"
   },
   "source": [
    "## Augmentation techniques\n",
    "\n",
    "In this notebook, we illustrate how the following augmentation techniques can be applied to the downloaded dataset:\n",
    "- Horizontal flip.\n",
    "- Shearing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwG_kg6Tni8k"
   },
   "source": [
    "## Installing the necessary libraries\n",
    "\n",
    "In case that CLODSA is not installed in your system, the first task consists in installing it using ``pip``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "z7qMC41Xni8k",
    "outputId": "51dca5c0-72ec-4fe2-cdce-81a4fb5c5873"
   },
   "outputs": [],
   "source": [
    "!pip install clodsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoxKQxZJni8q"
   },
   "source": [
    "## Loading the necessary libraries\n",
    "\n",
    "The first step in the pipeline consists in loading the necessary libraries to apply the data augmentation techniques in CLODSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yzMR_9kBni8s",
    "outputId": "16fe5d55-95d6-4329-ad41-a55aa19afdb3"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
    "from clodsa.transformers.transformerFactory import transformerGenerator\n",
    "from clodsa.techniques.techniqueFactory import createTechnique\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "85NJIbHRni8y"
   },
   "source": [
    "## Creating the augmentor object\n",
    "\n",
    "As explained in the documentation of CLODSA, we need to specify some parameters for the augmentation process, and use them to create an augmentor object.  \n",
    "\n",
    "_The kind of problem_. In this case, we are working in a stackdetection problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udjKKpIMni80"
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"stackdetection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AYs7FXmFni86"
   },
   "source": [
    "_The annotation mode_. The annotation is youtubevideo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROmfoBePni88"
   },
   "outputs": [],
   "source": [
    "ANNOTATION_MODE = \"youtubevideo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFmLaCVzni9A"
   },
   "source": [
    "_The input path_. The input path containing the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4qLXr7Hni9E"
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = \"youtube/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsxyfUVVni9K"
   },
   "source": [
    "_The generation mode_. In this case, linear, that is, all the augmentation techniques are applied to all the videos of the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXHMv0Djni9K"
   },
   "outputs": [],
   "source": [
    "GENERATION_MODE = \"linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P03YdvTTni9Q"
   },
   "source": [
    "_The output mode_. The generated videos will be stored in a new folder called augmented_videos_youtube. We must also provide the name of the csv with the annotations. That file must be in the same folder as the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFboWqIcni9Q"
   },
   "outputs": [],
   "source": [
    "OUTPUT_MODE = \"youtubevideo\"\n",
    "OUTPUT_PATH= \"augmented_videos_youtube/\"\n",
    "CSV = \"yotube_bb_detection_subset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG1harcAni9U"
   },
   "source": [
    "Using the above information, we can create our augmentor object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OH7Xy3rIni9W"
   },
   "outputs": [],
   "source": [
    "augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"csv\":CSV})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3es15zWQni9a"
   },
   "source": [
    "## Adding the augmentation techniques\n",
    "\n",
    "Now, we define the techniques that will be applied in our augmentation process and add them to our augmentor object. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we must define a transformer generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformerGenerator(PROBLEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zpB7VSoni9-"
   },
   "source": [
    "#### Horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6GhHPJxni-A"
   },
   "outputs": [],
   "source": [
    "hFlip = createTechnique(\"flip\",{\"flip\":1})\n",
    "augmentor.addTransformer(transformer(hFlip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shearing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shearing = createTechnique(\"shearing\", {\"a\":0.5})\n",
    "augmentor.addTransformer(transformer(shearing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTZLwyr_ni-4"
   },
   "source": [
    "#### None\n",
    "(to keep also the original video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XnKlw1Vni-4"
   },
   "outputs": [],
   "source": [
    "none = createTechnique(\"none\",{})\n",
    "augmentor.addTransformer(transformer(none))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nInbOZQHni_A"
   },
   "source": [
    "## Applying the augmentation process\n",
    "\n",
    "Finally, we apply the augmentation process (this might take some time depending on the number of videos of the original dataset and the number of transformations that will be applied). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVuonlNLni_A"
   },
   "outputs": [],
   "source": [
    "augmentor.applyAugmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdW54yfhni_C"
   },
   "source": [
    "Finally, we can check the amount of videos in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yR5dWTCDni_E"
   },
   "outputs": [],
   "source": [
    "print(\"Number of videos in folder\")\n",
    "!ls augmented_videos_youtube/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jf9ab-kZa1Rw"
   },
   "source": [
    "If you are executing this notebook in Colaboratory, you need to download the generated files. To that aim, you can create a zip folder and download it using the following commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT3J6-Sra_jg"
   },
   "outputs": [],
   "source": [
    "!zip -r augmented_videos_youtube.zip augmented_videos_youtube\n",
    "from google.colab import files\n",
    "files.download('augmented_videos_youtube.zip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CLODSA_Melanoma.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
